{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange the results;\n",
    "- Compare different normalization methods;\n",
    "- Compare different features;\n",
    "- Compare different image filters;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "from mySettings import get_arrange_results_settings_dict\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.myUtils import traversalDir_FirstDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Arrange and save all the experiment results into an excel file.\n",
    "\"\"\"\n",
    "def arrange_results_to_excel(experiment_results_bathpath):\n",
    "    \n",
    "    # Data frame to save the arranged results;\n",
    "    Arranged_Results=None\n",
    "    \n",
    "    image_filter_list=traversalDir_FirstDir(experiment_results_bathpath)\n",
    "    for image_filter in image_filter_list:\n",
    "        # folder 1: image_type, for example, {original, exponential, ...}\n",
    "        \n",
    "        # add some additional descriptions for the experiments;\n",
    "        image_filter_split=image_filter.split(\"_\")\n",
    "        if len(image_filter_split)>1:\n",
    "            image_filter_name=image_filter_split[0]\n",
    "            additional_description=image_filter_split[1]\n",
    "        else:\n",
    "            image_filter_name=image_filter\n",
    "            additional_description=\"\"\n",
    "        \n",
    "        basePath_image_filter=os.path.join(experiment_results_bathpath, image_filter)\n",
    "        experiment_description_list=traversalDir_FirstDir(basePath_image_filter)\n",
    "        \n",
    "        for experiment_description in experiment_description_list:\n",
    "            # folder 2: description of the expriments, for example, {TCGA_IDH_extracted_features_fcm, TCGA_IDH_extracted_features_no_normalization, TCGA_IDH_extracted_features_zscore}\n",
    "            normalization_method=experiment_description.split(\"-\")[-1]\n",
    "            \n",
    "            basePath_experiment_description=os.path.join(basePath_image_filter, experiment_description)\n",
    "            harmonization_method_list=traversalDir_FirstDir(basePath_experiment_description)\n",
    "            \n",
    "            for harmonization_method in harmonization_method_list:\n",
    "                # folder 3: Harmonization method and data imbalance strategy;\n",
    "                ComBat_method=harmonization_method.split(\"-\")[0]\n",
    "                Data_imblance_strategy=harmonization_method.split(\"-\")[1]\n",
    "                \n",
    "                basePath_harmonization=os.path.join(basePath_experiment_description, harmonization_method)\n",
    "                task_list=traversalDir_FirstDir(basePath_harmonization)\n",
    "                \n",
    "                for task in task_list:\n",
    "                    # folder 4: Task list, for example,[\"TCGA_1.101_isGBM_base\", \"TCGA_2.101_isIDHMutant_base\", \"TCGA_3.101_is1p19qCodeleted_base\"]\n",
    "                    base_task=task.split(\"_\")[2]\n",
    "                    task_additional_description=task.split(\"_\")[3]\n",
    "               \n",
    "                    #print(\"\\n- image_type={}, experiment_description={}, harmonization_method={}, task={}\".format(image_type, experiment_description, harmonization_method, task))\n",
    "                    basePath_task=os.path.join(basePath_harmonization, task)\n",
    "                    AUC_results_txt_file=os.path.join(basePath_task, \"AUC_results_all_models.txt\")\n",
    "                    \n",
    "                    AUC_results=pd.read_csv(AUC_results_txt_file, header=0, index_col=0)\n",
    "                    AUC_results.insert(0, \"image_filter\", image_filter_name)\n",
    "                    AUC_results.insert(1, \"normalization_method\", normalization_method)\n",
    "                    AUC_results.insert(2, \"ComBat_method\", ComBat_method)\n",
    "                    AUC_results.insert(3, \"Data_imblance_strategy\", Data_imblance_strategy)\n",
    "                    AUC_results.insert(4, \"task\", task)\n",
    "                    AUC_results.insert(5, \"base_task\", base_task)\n",
    "                    AUC_results.insert(6, \"task_additional_description\", additional_description+\" \"+task_additional_description)\n",
    "                    AUC_results.insert(7, \"additional_description\", additional_description)\n",
    "                    \n",
    "                    if isinstance(Arranged_Results, pd.DataFrame):\n",
    "                        Arranged_Results=pd.concat([Arranged_Results, AUC_results], axis=0)\n",
    "                    else:\n",
    "                        Arranged_Results=AUC_results\n",
    "                    \n",
    "    # add a column to tell feature selection method and classifier\n",
    "    Arranged_Results[\"feature_selection\"]=Arranged_Results[\"model_name\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    Arranged_Results[\"classifier\"]=Arranged_Results[\"model_name\"].apply(lambda x: x.split(\"_\")[1])\n",
    "    \n",
    "    # save the results\n",
    "    save_arranged_excel_path=os.path.join(experiment_results_bathpath, \"arranged_results.xlsx\")\n",
    "    Arranged_Results.reset_index(drop=True, inplace=True)\n",
    "    Arranged_Results.to_excel(save_arranged_excel_path)\n",
    "    \n",
    "    return Arranged_Results, save_arranged_excel_path\n",
    "\n",
    "\n",
    "def convert_list_in_dataframe(data_df):\n",
    "    \"\"\"\n",
    "    In the data frame, \"AUC\" correpsonds to a list of AUC cross validation values,\n",
    "    now we want to expand one record to len(AUC) records, so that we can draw the mean/media and std of the AUC values.\n",
    "    \"\"\"\n",
    "    \n",
    "    temp_AUC=data_df[\"AUC\"].str.strip(\"[\").str.strip(\"]\").str.replace(\" \", \",\").str.split(\",\", expand=True).stack()\n",
    "    temp_AUC=temp_AUC.reset_index(level=1, drop=True).rename(\"AUC_values\")\n",
    "    data_df=data_df.join(temp_AUC)\n",
    "    data_df[\"AUC_values\"] = pd.to_numeric(data_df[\"AUC_values\"], errors='raise')\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "\n",
    "def add_median_labels(ax, precision='.4f'):\n",
    "    \"\"\"\n",
    "    add annotation for the box plots.\n",
    "    \n",
    "    References: https://stackoverflow.com/questions/38649501/labeling-boxplot-in-seaborn-with-median-value.\n",
    "    \"\"\"\n",
    "    lines = ax.get_lines()\n",
    "    boxes = [c for c in ax.get_children() if type(c).__name__ == 'PathPatch']\n",
    "    lines_per_box = int(len(lines) / len(boxes))\n",
    "    for median in lines[4:len(lines):lines_per_box]:\n",
    "        x, y = (data.mean() for data in median.get_data())\n",
    "        # choose value depending on horizontal or vertical plot orientation\n",
    "        value = x if (median.get_xdata()[1] - median.get_xdata()[0]) == 0 else y\n",
    "        text = ax.text(x, y, f'{value:{precision}}', ha='center', va='center',\n",
    "                       fontweight='normal', fontsize=5, color='white')\n",
    "        # create median-colored border around white text for contrast\n",
    "        text.set_path_effects([\n",
    "            path_effects.Stroke(linewidth=3, foreground=median.get_color()),\n",
    "            path_effects.Normal(),\n",
    "        ])\n",
    "        \n",
    "        \n",
    "def visualize_rranged_results(arranged_excel_path, groupby_column, plot_setting, plot_type=\"boxplot\"):\n",
    "    \"\"\"\n",
    "    Plot the results in a bar plot for better visualization.\n",
    "    \"\"\"\n",
    "    ## read plot settings\n",
    "    x_column=plot_setting[\"x_column\"]\n",
    "    hue_column=plot_setting[\"hue_column\"]\n",
    "    rename_hue_values=plot_setting[\"rename_hue_values\"]\n",
    "    exclude_hue_value_list=plot_setting[\"exclude_hue_value\"]\n",
    "    ncol=plot_setting[\"ncol\"]\n",
    "        \n",
    "    \n",
    "    ## read data\n",
    "    Arranged_Results=pd.read_excel(arranged_excel_path, index_col=0)\n",
    "    Arranged_Results[hue_column+\"_renamed\"] = Arranged_Results[hue_column].map(rename_hue_values)\n",
    "    \n",
    "    ## do not show XGBClassifier results because XGBClassifier are not totally reproducible for now.\n",
    "    Arranged_Results.drop(Arranged_Results[Arranged_Results[\"classifier\"]==\"XGBClassifier\"].index, inplace=True)\n",
    "    \n",
    "    ## do not plot some experiments;\n",
    "    if len(exclude_hue_value_list)>0:\n",
    "        for exclude_hue_value in exclude_hue_value_list:\n",
    "            Arranged_Results.drop(Arranged_Results[Arranged_Results[hue_column]==exclude_hue_value].index, inplace=True)\n",
    "            \n",
    "    ## save the results  \n",
    "    save_bathpath=os.path.dirname(arranged_excel_path)\n",
    "    save_excel_path=os.path.join(save_bathpath, \"arranged_results_\"+x_column+\"-\"+hue_column+\".xlsx\")\n",
    "    writer = pd.ExcelWriter(save_excel_path)\n",
    "\n",
    "    ## Analyze the results.\n",
    "    for task, task_results_df in Arranged_Results.groupby([groupby_column], sort=True):\n",
    "        print(\"\\n\\n ***********  task={} ******************\".format(task))\n",
    "        ## plot\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.xticks(size=12)\n",
    "        plt.yticks(size=12)\n",
    "        plt.xlabel(x_column,size=16)\n",
    "        \n",
    "        if plot_type==\"barplot\": \n",
    "            # bar plot\n",
    "            ax=sns.barplot(x=x_column, y=\"median_AUC\", hue=hue_column+\"_renamed\", hue_order=rename_hue_values.values(), data=task_results_df, palette=\"Paired\") \n",
    "            \n",
    "            # add text on the bar plots\n",
    "            for p in ax.patches:\n",
    "                color=p.get_facecolor()\n",
    "                box = p.get_bbox()\n",
    "                ax.annotate(\"%.4f\" % p.get_height(), xy=((box.x0 + box.x1)/2-0.02, p.get_height()+0.02), color=color, \n",
    "                            rotation=90, fontsize=8, weight='bold')\n",
    "                \n",
    "            # some settings\n",
    "            plt.ylim((0.5, 1.1))\n",
    "            plt.ylabel('median AUC',size=16)\n",
    "            save_fig_name=os.path.join(save_bathpath, task.replace(\".\", \"-\")+\"_barplot.jpeg\")\n",
    "                                       \n",
    "        elif plot_type==\"boxplot\":  \n",
    "            # box plot\n",
    "            converted_task_results_df=convert_list_in_dataframe(task_results_df)\n",
    "            ax=sns.boxplot(x=x_column, y=\"AUC_values\",  hue=hue_column+\"_renamed\", hue_order=rename_hue_values.values(), \n",
    "                           showmeans=True, data=converted_task_results_df, palette=\"Paired\") \n",
    "            \n",
    "            # add text next to the box.\n",
    "            add_median_labels(ax)\n",
    "                                       \n",
    "            # some settings\n",
    "            plt.ylabel('AUC',size=16)\n",
    "            save_fig_name=os.path.join(save_bathpath, task.replace(\".\", \"-\")+\"_boxplot.jpeg\")\n",
    "        \n",
    "\n",
    "        # settings of the plots\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width , box.height* 0.8])\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=ncol)\n",
    "        #ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0, ncol=1)\n",
    "        plt.subplots_adjust(left=0.07, bottom=0.2, right=0.98, top=0.85, wspace =0, hspace =0)\n",
    "        plt.xticks(rotation=15)\n",
    "        plt.grid()\n",
    "        plt.savefig(save_fig_name, dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        #save to the excel\n",
    "        task_results_df.sort_values(\"median_AUC\", ascending=False, inplace=True)\n",
    "        task_results_df.to_excel(writer, sheet_name=task)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arrange_results_settings_dict=get_arrange_results_settings_dict()\n",
    "for arrange_name, arrange_results_settings in arrange_results_settings_dict.items():\n",
    "    results_basepath=arrange_results_settings[\"results_basepath\"]\n",
    "    groupby_column=arrange_results_settings[\"groupby_column\"]\n",
    "    plot_setting=arrange_results_settings[\"plot_setting\"]\n",
    "    \n",
    "    ## Arrange the results;\n",
    "    Arranged_Results, save_arranged_excel_path=arrange_results_to_excel(results_basepath)\n",
    "    print(\"\\n\\n =========================== Arranged Results ====================================\")\n",
    "    display(Arranged_Results.head())\n",
    "    \n",
    "    ## Visualize the arranged results;\n",
    "    visualize_rranged_results(save_arranged_excel_path, groupby_column, plot_setting)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
