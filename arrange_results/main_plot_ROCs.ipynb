{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the ROC curves with different random seeds in one plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils.VisualizationUtils import get_color_list\n",
    "from mySettings import get_plot_ROC_setting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutiple_ROCs(data_df_dict, task_name, save_results_path):\n",
    "    \"\"\"\n",
    "    Plot multiple ROC curves in one plot.\n",
    "    \"\"\"\n",
    "\n",
    "    fpr_dict=dict()\n",
    "    tpr_dict=dict()\n",
    "    roc_auc_dict=dict()\n",
    "    \n",
    "    ## --- calcuate for random seed. -------\n",
    "    y_true=[]\n",
    "    y_predicted_prob=[]\n",
    "    num_labels=len(data_df_dict)\n",
    "    for label, data_df in data_df_dict.items():\n",
    "        y_true_i=data_df[task_name+\"-true\"].values\n",
    "        y_pred_i=data_df[task_name+\"-predicted_prob\"].values\n",
    "        \n",
    "        # save all the values for calculate the micro average.\n",
    "        if len(y_true)==0:\n",
    "            y_true=y_true_i\n",
    "            y_predicted_prob=y_pred_i\n",
    "        else:\n",
    "            y_true=[*y_true, *y_true_i]\n",
    "            y_predicted_prob=[*y_predicted_prob, *y_pred_i]\n",
    "        \n",
    "        # calculate the fpr/tpr values and AUC\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_true_i, y_pred_i)\n",
    "        roc_auc_score = metrics.auc(fpr, tpr)  \n",
    "        \n",
    "        # save the fpr/tpr/AUC in the dict.\n",
    "        fpr_dict[label]=fpr\n",
    "        tpr_dict[label]=tpr\n",
    "        roc_auc_dict[label]=roc_auc_score\n",
    "   \n",
    "\n",
    "    ## --- calculate the macro averaage. ----------\n",
    "    # aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr_dict[key] for key in fpr_dict.keys()]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for key in fpr_dict.keys():\n",
    "        mean_tpr += np.interp(all_fpr, fpr_dict[key], tpr_dict[key])\n",
    "        \n",
    "    mean_tpr /= num_labels\n",
    "\n",
    "    fpr_dict[\"macro\"] = all_fpr\n",
    "    tpr_dict[\"macro\"] = mean_tpr\n",
    "    roc_auc_dict[\"macro\"] = metrics.auc(fpr_dict[\"macro\"], tpr_dict[\"macro\"])\n",
    "    \n",
    "    ## ---- calculate the micro average. --------\n",
    "    fpr_dict[\"micro\"], tpr_dict[\"micro\"], _ = metrics.roc_curve(y_true, y_predicted_prob)\n",
    "    roc_auc_dict[\"micro\"] = metrics.auc(fpr_dict[\"micro\"], tpr_dict[\"micro\"]) \n",
    "    \n",
    "    \n",
    "    ## ----- Plot the ROC curve. -------------\n",
    "    #colors=get_color_list()\n",
    "    colors=list(mcolors.CSS4_COLORS)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    i=0\n",
    "    for label, auc in roc_auc_dict.items():\n",
    "        fpr=fpr_dict[label]\n",
    "        tpr=tpr_dict[label]\n",
    "        if label in [\"micro\", \"macro\"]:\n",
    "            plt.plot(fpr, tpr,  color=colors[i],  linestyle=\":\",  lw=4, label=label+\"-average ROC curve (area = {0:0.4f})\".format(roc_auc_dict[label]))\n",
    "        else:\n",
    "            plt.plot(fpr, tpr,  color=colors[i],  lw=2,  label=\"ROC curve for {0} (area = {1:0.4f})\".format(label, roc_auc_dict[label]))\n",
    "\n",
    "        i=i+1\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    #plt.title(\"Receiver Operating Characteristic Curves\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_results_path, task_name+\"-ROC_curves_all.jpeg\"))  \n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Plot the ROC curves with different random seeds in one plot;\n",
    "plot_ROC_setting_dict=get_plot_ROC_setting_dict()\n",
    "for setting_name, plot_ROC_setting in plot_ROC_setting_dict.items():\n",
    "    # basic settings\n",
    "    base_dataPath=plot_ROC_setting[\"base_dataPath\"]\n",
    "    random_seed_list=plot_ROC_setting[\"random_seed_list\"]\n",
    "    save_results_path=plot_ROC_setting[\"save_results_basepath\"]\n",
    "    data_excel_name=plot_ROC_setting[\"data_excel_name\"]\n",
    "    task_list=plot_ROC_setting[\"task_list\"]\n",
    "    \n",
    "    # put the data frame for different random seeds into a list.\n",
    "    data_df_dict={}\n",
    "    for random_seed in random_seed_list:\n",
    "        data_excel_path=os.path.join(base_dataPath, \"seed\"+str(random_seed), data_excel_name) \n",
    "        data_df=pd.read_excel(data_excel_path, index_col=0)\n",
    "        data_df_dict[\"seed \"+str(random_seed)]=data_df\n",
    "        \n",
    "    # plot the ROC curves.\n",
    "    for task_name in task_list:\n",
    "        plot_mutiple_ROCs(data_df_dict, task_name, save_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
